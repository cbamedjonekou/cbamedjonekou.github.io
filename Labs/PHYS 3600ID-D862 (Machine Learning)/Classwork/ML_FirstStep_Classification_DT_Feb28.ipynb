{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use some material from\n",
    "\n",
    "https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "\n",
    "The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "and take inspiration from\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several Python libraries which provide solid implementations of a range of machine learning algorithms.\n",
    "One of the best known is [Scikit-Learn](http://scikit-learn.org), a package that provides efficient versions of a large number of common algorithms.\n",
    "\n",
    "A benefit of this uniformity is that once you understand the basic use and syntax of Scikit-Learn for one type of model, switching to a new model or algorithm is very straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use scikit-learn, of course we have to import it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is about creating models from data: for that reason, we'll start by discussing how data can be represented in order to be understood by the computer.\n",
    "The best way to think about data within Scikit-Learn is in terms of tables of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data as table\n",
    "\n",
    "A basic table is a two-dimensional grid of data, in which the rows represent individual elements of the dataset, and the columns represent quantities related to each of these elements.\n",
    "For example, consider the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), famously analyzed by Ronald Fisher in 1936.\n",
    "\n",
    "We will use the easiest way to import data, to avoid introducing more packages than we need. \n",
    "\n",
    "<b> More advanced Python programmers would want to have a look at using the [seaborn](http://seaborn.pydata.org/) library for data visualization.</b>\n",
    "\n",
    "Many well know data sets have already been included in scikit-learn, so to load one into memory we can just do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the .data member, which is a n_samples, n_features array. In the case of a supervised problem, one or more response variables are stored in the .target member. More details on the different datasets can be found [here](http://scikit-learn.org/stable/datasets/index.html#datasets). \n",
    "\n",
    "And some detail about this particular data set is here:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data #note that this is a numpy array, so it allows any array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each row of the data refers to a single observed flower, and the number of rows is the total number of flowers in the dataset.\n",
    "In general, we will refer to the rows of the matrix as *samples*, and the number of rows as ``n_samples``.\n",
    "\n",
    "Likewise, each column of the data refers to a particular quantitative piece of information that describes each sample.\n",
    "In general, we will refer to the columns of the matrix as *features*, and the number of columns as ``n_features``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the expected layout of features and target values is visualized in the following diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](05.02-samples-features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: How many features are in this data set? How many objects?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 features and 150 objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Iris data set, the four features are:\n",
    "\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "\n",
    "and the target values are\n",
    "\n",
    "-- Iris Setosa (0)\n",
    "-- Iris Versicolour (1)\n",
    "-- Iris Virginica (2).\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#The names of features and target classes (if available) for sklearn data \n",
    "#sets can be found as follows:\n",
    "\n",
    "print(iris.feature_names)\n",
    "\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My favorite (unofficial) machine learning textbook is\n",
    "\n",
    "http://scikit-learn.org/stable/tutorial/index.html\n",
    "\n",
    "If you want to see all the examples that use the Iris data set, you can just use the custom Google\n",
    "search in that page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The golden rule of data science: know what your data looks like before starting!\n",
    "\n",
    "We have four features, which means our data space has four dimensions, plus the target. This makes it a bit difficult to visualize all of it.\n",
    "\n",
    "In general, we should at least:\n",
    "\n",
    "1. check that all the features are in a similar numerical range (and if not, normalize them!), \n",
    "\n",
    "2. check whether the data set is very imbalanced (e.g. one or more classes are much more common than others)\n",
    "\n",
    "3. check if lots of data are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1134bcb70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1134bcc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's take a look at histograms of the features\n",
    "\n",
    "for i in range(iris.data.shape[1]):\n",
    "    plt.hist(iris.data[:,i],alpha=0.3,histtype='stepfilled',label = 'Feature'+str(i));\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117e6be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's take a look at the histogram of the possible classes\n",
    "plt.hist(iris.target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neat trick to figure out how many possible classes/outputs you have\n",
    "\n",
    "np.unique(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of building a machine learning classifier using scikit-learn\n",
    "\n",
    "Now the task is to take a portion of these data as train set, build a model, and predict the labels of the remaining portion (test set). The steps will usually be the following:\n",
    "\n",
    "1. Choose a class of model (aka a machine learning algorithm) by importing the appropriate estimator class from Scikit-Learn.\n",
    "\n",
    "2. Choose model hyperparameters by instantiating this class with desired values.  Alternatively: optimize hyperparameters (later).\n",
    "\n",
    "3. Arrange data into a features matrix and target vector, if necessary.\n",
    "\n",
    "4. Split the learning set into training/test (more on cross-validation later).\n",
    "\n",
    "5. Fit the model to your data by calling the ``fit()`` method of the model instance.\n",
    "\n",
    "6. Apply the Model to new data:\n",
    "   - For supervised learning, often we predict labels for unknown data using the ``predict()`` method.\n",
    "   - For unsupervised learning, we often transform or infer properties of the data using the ``transform()`` or ``predict()`` method.\n",
    "   \n",
    "7. Estimate the performance by using one of the metrics in the \"metrics\" method of the model instance.\n",
    "\n",
    "8. Rejoice (unlikely), figure out what is not working out and repeat from 1 (likely)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first classifier: a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time for us to build our first, very simple, classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are extremely intuitive ways to classify or label objects: you simply ask a series of questions designed to zero-in on the classification.\n",
    "For example, if you wanted to build a decision tree to classify an animal you come across while on a hike, you might construct the one shown here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](05.08-decision-tree.png \"A decision tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary splitting makes this extremely efficient. <b> In a well-constructed tree, each question will cut the number of options by approximately half, </b> very quickly narrowing the options even among a large number of classes. \n",
    "\n",
    "<b> The trick, of course, comes in deciding which questions to ask at each step. </b>\n",
    "\n",
    "In machine learning implementations of decision trees, the questions generally take the form of axis-aligned splits in the data: that is, <b> each node in the tree splits the data into two groups using a cutoff value within one of the features. </b>\n",
    "Let's now look at an example of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process of fitting a decision tree to our data can be done in Scikit-Learn with the ``DecisionTreeClassifier`` [estimator](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Choose a class of model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Choose model hyperparameters by instantiating this class with desired values. \n",
    "\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Arrange data into a features matrix and target vector, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Split the learning set into training/test (more on cross-validation later).\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data, iris.target, \\\n",
    "                                                test_size = 0.33, \\\n",
    "                                                random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Fit the model to your data by calling the ``fit()`` method of the model instance.\n",
    "\n",
    "model.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. Apply the Model to create an array of predictions on test set data:\n",
    "\n",
    "ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Estimate the performance by using one of the metrics \n",
    "# in the \"metrics\" method of the model instance.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can repeat the procedure for another random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain2, Xtest2, ytrain2, ytest2 = train_test_split(iris.data, iris.target, \\\n",
    "                                                test_size = 0.33, \\\n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain2,ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2 = model.predict(Xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest2,ypred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can get a more precise account of the classification results by looking \n",
    "# at the confusion matrix (peek from next class!)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is just a function that plots them\n",
    "\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(ytest2, ypred2)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=iris.target_names,\n",
    "                      title='Confusion matrix')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
