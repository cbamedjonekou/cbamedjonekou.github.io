{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('Datasets/RRLyrae_features.txt',delimiter=',')\n",
    "y = np.genfromtxt('Datasets/RRLyrae_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the data set to see if it's balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 92658)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y > 0.5), np.sum(y < 0.5) #trick to count objects with label 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC #Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC() # What is this doing to the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with one single train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, \\\n",
    "                                                test_size = 0.2, \\\n",
    "                                                random_state=0) \n",
    "\n",
    "\n",
    "model.fit(Xtrain,ytrain)\n",
    "\n",
    "ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99559826077620917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To judge the extent of our problem we can use 5-fold cross validation. This will show us if the problem is relative to this particular train/test split or not.\n",
    "\n",
    "As a reminder, cross_val_score picks k (in our case, 5) different disjoint folds, using one fold at a time as the test set, and the other k-1 (in our case, 4) as training set, and averages the test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring= 'accuracy') # What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99479306,  0.99479306,  0.99479306,  0.99484619,  0.99484619])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring= 'recall') # What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is so imbalanced that SVCs are creating a classifier that says everything is negative! To proceed more quickly, let's work with a smaller data set that has also been artificially balanced by me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xlittle = np.genfromtxt('RRLyrae_features_small.txt',delimiter=',')\n",
    "ylittle = np.genfromtxt('RRLyrae_labels_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2483,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylittle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ylittle > 0.5), np.sum(ylittle < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913793103448\n",
      "0.969818913481\n",
      "0.954954954955\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xlittle, ylittle, \\\n",
    "                                                test_size = 0.2, \\\n",
    "                                                random_state=2) \n",
    "\n",
    "model.fit(Xtrain,ytrain)\n",
    "\n",
    "ypred = model.predict(Xtest)\n",
    "\n",
    "print(metrics.recall_score(ypred,ytest))\n",
    "\n",
    "print(metrics.accuracy_score(ypred,ytest))\n",
    "\n",
    "print(metrics.precision_score(ypred,ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are using a built-in cross validation function called Stratified KFold. This means that the folds that will be created will approximately maintain the same class distribution of the original data set. This is useful in an imbalanced data set. The \"shuffle = True\" option ensures that we shuffle the data set before proceeding, useful if the classes are in order (e.g. all the zeros in the beginning, all the ones at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylittle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97938144  0.97938144  1.          0.9375      0.95833333]\n",
      "0.970919243986\n",
      "0.0212798450198\n"
     ]
    }
   ],
   "source": [
    "model = SVC() \n",
    "cvmethod = StratifiedKFold(shuffle=True, n_splits=5) # this ensures that folds are randomized\n",
    "scores = cross_val_score(model, Xlittle, ylittle, cv=cvmethod, \\\n",
    "                         scoring= 'recall') # What does this do?\n",
    "print(scores) \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stuff above gives us an idea of the SVC performance. Let's compare it to our old friend the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93814433  0.91752577  0.94845361  0.90625     0.9375    ]\n",
      "0.929574742268\n",
      "0.0153745268577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier() #Leaving params at default value for now\n",
    "\n",
    "scores = cross_val_score(model, Xlittle, ylittle, cv=cvmethod, \\\n",
    "                         scoring= 'recall') # What does this do?\n",
    "\n",
    "print(scores) \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like SVC is superior to Decision Trees even with no parameter optimization. But let's see if we can do better with nested cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do one parameter search on our own just to see how it works and then use sklearn's built-in function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to optimize the parameter C, the soft margin. Possible values are C = [1, 10, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important! COMMENT\n",
    "\n",
    "#Outer k-fold:\n",
    "    \n",
    "outercv = StratifiedKFold(n_splits=5, shuffle=True) #creates 5 disjoint splits\n",
    "\n",
    "innercv = StratifiedKFold(n_splits=4, shuffle=True) #creates 4 disjoint splits\n",
    "\n",
    "C = [1,10,100]\n",
    "\n",
    "i=0\n",
    "\n",
    "winning_model_scores = []\n",
    "\n",
    "for train_index, test_index in outercv.split(Xlittle,ylittle): #This runs the outer cross validation\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    print('Fold ' ,i, 'outer cross validation')\n",
    "    \n",
    "    Xlittle_train = Xlittle[train_index] #This is my \"yellow\" training set where I do the inner CV\n",
    "    ylittle_train = ylittle[train_index]\n",
    "    \n",
    "    Xlittle_test = Xlittle[test_index]\n",
    "    ylittle_test = ylittle[test_index]\n",
    "    \n",
    "    temp_scores = []\n",
    "    \n",
    "    for Cvalue in C:\n",
    "        \n",
    "        model = SVC(C=Cvalue)\n",
    "\n",
    "        scores = cross_val_score(model, Xlittle_train, ylittle_train, \\\n",
    "                                 cv=innercv, scoring= 'recall') \n",
    "        \n",
    "        print('C =', Cvalue, 'Mean score over 4 inner folds =', \\\n",
    "              \"{:.4f}\".format(np.mean(scores)))\n",
    "    \n",
    "        temp_scores.append(np.mean(scores))\n",
    "    \n",
    "    print('Winning model has C =', C[np.argmax(temp_scores)]), \\\n",
    "        'and score = ', temp_scores[np.argmax(temp_scores)]\n",
    "\n",
    "    # Now we set the parameters of the SVC to the best C we just found, fit the model \n",
    "    # and predict labels of of test set for each outer (blue) fold\n",
    "    \n",
    "    model = SVC(C = C[np.argmax(temp_scores)])\n",
    "    \n",
    "    model.fit(Xlittle_train, ylittle_train)\n",
    "    \n",
    "    ypred = model.predict(Xlittle_test)\n",
    "    \n",
    "    winning_model_scores.append(metrics.recall_score(ylittle_test,ypred)) #append this to the outer cv results\n",
    "    \n",
    "print('The average of the winning model scores \\\n",
    "    (i.e. the generalization error) is', \\\n",
    "      \"{:.4f}\".format(np.mean(winning_model_scores)), \\\n",
    "      \"{:.4f}\".format(np.std(winning_model_scores) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't actually need to do this by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time #This is to see how long things take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizing SVC: this replaces the inner loop!\n",
    "#Important! \n",
    "\n",
    "parameters = {'kernel':['rbf','poly'], \\\n",
    "              'gamma':[0.01, 0.1, 0.5], 'C':[1,10,100]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "start = time.time()\n",
    "model = GridSearchCV(SVC(), parameters, cv = innercv, scoring = 'recall', \\\n",
    "                     verbose = 1, n_jobs = 4)\n",
    "model.fit(Xlittle_train, ylittle_train)\n",
    "stop = time.time()\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)\n",
    "print('Time per model (s):', \"{:.4f}\".format((stop-start)/float(nmodels*4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now putting everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important! COMMENT\n",
    "\n",
    "#Outer k-fold:\n",
    "    \n",
    "outercv = StratifiedKFold(n_splits=5, shuffle=True) #creates 5 disjoint splits\n",
    "\n",
    "innercv = StratifiedKFold(n_splits=4, shuffle=True) #creates 4 disjoint splits\n",
    "\n",
    "i=0\n",
    "\n",
    "winning_model_scores = []\n",
    "\n",
    "for train_index, test_index in outercv.split(Xlittle,ylittle): #This runs the outer cross validation\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    print('Fold ' ,i, 'outer cross validation')\n",
    "    \n",
    "    Xlittle_train = Xlittle[train_index] #\"yellow\" training set\n",
    "    ylittle_train = ylittle[train_index]\n",
    "    \n",
    "    Xlittle_test = Xlittle[test_index]\n",
    "    ylittle_test = ylittle[test_index]\n",
    "    \n",
    "    #optimizing SVC: this replaces the inner loop!\n",
    "    \n",
    "    parameters = {'kernel':['rbf','poly'], \\\n",
    "              'gamma':[0.01, 0.1, 0.5], 'C':[1,10,100]}\n",
    "    nmodels = np.product([len(el) for el in parameters.values()])\n",
    "    start = time.time()\n",
    "    model = GridSearchCV(SVC(), parameters, cv = innercv, scoring = 'recall', \\\n",
    "                     verbose = 1, n_jobs = 4)\n",
    "    model.fit(Xlittle_train, ylittle_train)\n",
    "    stop = time.time()\n",
    "    print('Best params, best score:', \"{:.4f}\".format(model.best_score_), model.best_params_)\n",
    "    print('Time per model (s):', \"{:.4f}\".format((stop-start)/float(nmodels*4)))\n",
    "\n",
    "    #Compute test scores with optimal parameters on outer i-th test fold\n",
    "    \n",
    "    winner = model.best_estimator_\n",
    "    \n",
    "    winner.fit(Xlittle_train, ylittle_train)\n",
    "    \n",
    "    ypred = winner.predict(Xlittle_test)\n",
    "    \n",
    "    winning_model_scores.append(metrics.recall_score(ylittle_test,ypred)) #append this to the outer cv results\n",
    "    \n",
    "print('The average of the winning model scores (i.e. the generalization error) is', \\\n",
    "      np.mean(winning_model_scores), np.std(winning_model_scores) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: The performance that you can expect from your classifier is recall = ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced bit: Your final model will be built by doing grid-search CV on the full data set, and its anticipated generalization error will be the one given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this might have different params\n",
    "\n",
    "parameters = {'kernel':['rbf','poly'], \\\n",
    "              'gamma':[0.01, 0.1, 0.5], 'C':[1,10,100]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "start = time.time()\n",
    "model = GridSearchCV(SVC(), parameters, cv = innercv, scoring = 'recall', \\\n",
    "                     verbose = 1, n_jobs = 4)\n",
    "model.fit(Xlittle, ylittle)\n",
    "stop = time.time()\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), model.best_params_)\n",
    "print('Time per model (s):', \"{:.4f}\".format((stop-start)/float(nmodels*4)))\n",
    "\n",
    "#Final model\n",
    "\n",
    "model.best_estimator_.fit(Xlittle,ylittle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Do Grid Search CV on the full data set, varying for time's sake only gamma and the class weight, and setting the number of folds to be 3 in both inner and outer loops. In other words\n",
    "\n",
    "parameters = {'kernel':['rbf'],'C':[10], 'gamma':[0.01, 0.1, 0.5], 'class_weight':[{1:1},{1:3},{1:5},{1:7}]}\n",
    "\n",
    "Note: It might take some time (on my laptop it took ~ 10 minutes); set verbose = 2 if you want to follow the progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
