{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name: Christ-Brian Amedjonekou**  \n",
    "**Date: 03/18/2019**  \n",
    "**PHYS 3600ID-D862 (Machine Learning) HW 4**  \n",
    "**Spring 2019, Section: D862, Code: 37026**  \n",
    "**Instructor: Viviana Acquaviva**\n",
    "\n",
    "\n",
    "***I certify that my work is my own.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description\n",
    "\n",
    "The data we use for this worksheet are about stars. Our features are the so-called \"colors\", which give an indication of whether a star emits more blue, green, yellow, or red light. We are trying to predict whether a star is a special type of star called a RR-Lyrae variable star. So our target values will be yes/no (1/0 in the language of numpy arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data for features and target from the appropriate files and save them as numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.metrics import accuracy_score as acc, confusion_matrix as cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93141 entries, 0 to 93140\n",
      "Data columns (total 5 columns):\n",
      "Blue      93141 non-null float64\n",
      "Green     93141 non-null float64\n",
      "Yellow    93141 non-null float64\n",
      "Red       93141 non-null float64\n",
      "Target    93141 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "lyraeSet = pd.read_excel('Datasets/RRLyrae_full.xlsx')\n",
    "lyraeSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>Red</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394000</td>\n",
       "      <td>1.250999</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339001</td>\n",
       "      <td>1.048000</td>\n",
       "      <td>0.151999</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341999</td>\n",
       "      <td>1.008001</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.203001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333000</td>\n",
       "      <td>1.040001</td>\n",
       "      <td>0.125999</td>\n",
       "      <td>0.101999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.373999</td>\n",
       "      <td>1.154001</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.384001</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.118999</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.370998</td>\n",
       "      <td>1.015001</td>\n",
       "      <td>0.158001</td>\n",
       "      <td>0.091999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.391001</td>\n",
       "      <td>1.003000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.389999</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.168001</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.143999</td>\n",
       "      <td>0.092001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.390999</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.130001</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>0.028999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.985001</td>\n",
       "      <td>0.147999</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.329000</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.339001</td>\n",
       "      <td>1.011999</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.101999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.176001</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.373001</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>0.191999</td>\n",
       "      <td>0.073999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.353001</td>\n",
       "      <td>1.008999</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.060001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Blue     Green    Yellow       Red  Target\n",
       "0   0.394000  1.250999  0.137000  0.061999       0\n",
       "1   0.339001  1.048000  0.151999  0.023001       0\n",
       "2   0.341999  1.008001  0.129000  0.203001       0\n",
       "3   0.392000  0.965000  0.149000  0.150000       0\n",
       "4   0.333000  1.040001  0.125999  0.101999       0\n",
       "5   0.373999  1.154001  0.145000  0.121000       0\n",
       "6   0.384001  0.965000  0.118999  0.011000       0\n",
       "7   0.370998  1.015001  0.158001  0.091999       0\n",
       "8   0.391001  1.003000  0.145000  0.074999       0\n",
       "9   0.330000  0.948000  0.164000  0.021000       0\n",
       "10  0.389999  1.020000  0.168001  0.070999       0\n",
       "11  0.381001  0.997999  0.143999  0.092001       0\n",
       "12  0.390999  0.882000  0.130001  0.156000       0\n",
       "13  0.289000  0.851000  0.106001  0.028999       0\n",
       "14  0.392000  0.985001  0.147999  0.048000       0\n",
       "15  0.329000  0.914000  0.142000  0.077000       0\n",
       "16  0.339001  1.011999  0.166000  0.101999       0\n",
       "17  0.372000  0.864000  0.176001  0.070000       0\n",
       "18  0.373001  1.035000  0.191999  0.073999       0\n",
       "19  0.353001  1.008999  0.184000 -0.060001       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyraeSet.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Answer the following questions:\n",
    "\n",
    "Is this a classification or regression problem?\n",
    "\n",
    "* **Classification**\n",
    "\n",
    "Is this supervised or unsupervised learning?\n",
    "\n",
    "* **Supervised, target vector is present**\n",
    "\n",
    "How many instances are in this data set? \n",
    "\n",
    "* $\\mathbf{93141}$\n",
    "\n",
    "How many features? What is their range?\n",
    "\n",
    "* **4 features (colors: Blue, Green, Yellow, Red)**\n",
    "\n",
    "How many RR Lyrae are in the data set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of RR Lyrae Variable Stars: 483\n"
     ]
    }
   ],
   "source": [
    "print('Amount of RR Lyrae Variable Stars: {}'.format(lyraeSet[lyraeSet['Target'] == 1].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the accuracy of a classifier that classifies all objects in the data set as non-RR Lyrae?\n",
    "\n",
    "* **If '1' (RR Lyrae) is the negative class then accuracy = $0.5\\%$**\n",
    "    * I'm assuming for this to be the positive class\n",
    "    \n",
    "    \n",
    "* **If '0' (Non-RR Lyrae) is the negative class then accuracy = $99.5\\%$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy_(positive_class= 1):\n",
    "    amount = lyraeSet[lyraeSet['Target'] == positive_class].shape[0]\n",
    "    total = lyraeSet['Target'].shape[0]\n",
    "    return amount/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005185686217669985"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When 1 (RR Lyrae) is the positive class\n",
    "accuracy_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99481431378233"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When 0 (Non-RR Lyrae) is the positive class\n",
    "accuracy_(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very Unbalanced: Non-Lyrae are most common it appears**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lyraeSet['Target'], edgecolor= 'k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Build a decision tree classifier for this data set, using an 80/20 train test split like last time. What is the performance on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Model\n",
    "lyraeModel = DTC()\n",
    "\n",
    "# Since my Features and Targets are separated, \n",
    "# we'll create the train and test sets\n",
    "\n",
    "Data = lyraeSet[['Blue', 'Green', 'Yellow', 'Red']]\n",
    "Target = lyraeSet['Target']\n",
    "xtrain, xtest, ytrain, ytest = tts(Data, Target, test_size= 0.2, \n",
    "                                   train_size= 0.8, random_state= 5)\n",
    "\n",
    "# Now we'll fit the model with the training data\n",
    "lyraeModel.fit(xtrain, ytrain)\n",
    "\n",
    "# Now we'll test the model by making predictions on the test set\n",
    "ypred = lyraeModel.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the k-fold cross validation algorithm using the following syntax (note that this assumes that your algorithm is called 'model'):\n",
    "\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note: if you want to also save the predicted labels, you can do\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "ypred = cross_val_predict(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Report the scores, and calculate the mean and standard deviation of the scores vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Calculate and plot the confusion matrix for your model (Note: you will need to copy/paste the \"plot_confusion_matrix\" function from one of the previous notebooks, and use the function cross_val_predict to get the predicted labels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Based on the confusion matrix, how many true positive, true negative, false positive, false negative instances do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Based on the definitions given on the slides, calculate accuracy, precision and recall. <b>Important:</b> You need to use the formula, not the built-in functions, and write the steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Which evaluation metric is used by the cross validation score above? [To answer this question, you might need to check out the description of the function]. Given the distribution of classes in your data set, do you see a possible issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other evaluation metrics can be found in scikit using the code below.\n",
    "\n",
    "More info: http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.accuracy_score(ytest, ypred)    \n",
    "print metrics.recall_score(ytest, ypred)      \n",
    "print metrics.precision_score(ytest, ypred)   \n",
    "print metrics.f1_score(ytest, ypred)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. What happens to each of the metrics above if you flip y_test and y_pred in the above? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "10\\. To compare performance for now, let's use the F1 score, a weighted average of precision and recall.\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "Find out how to use the f1 score (instead of accuracy) as an optional argument of the cross_val_score function and report the mean and standard deviation of the scores associated to this evaluation metric.\n",
    "\n",
    "Relevant docs: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\. It is now time to look at some diagnostics. Use an 80/20 training split (so each fold is 20% of the data, like in your cross validation). Report the f1 score obtained by your model\n",
    "when applied to the training set (i.e. when you predict the labels of the training set). How does it compare with the cross validation score? Based on this result, do you think your algorithm suffers from high variance or high bias and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look at learning curves. \n",
    "\n",
    "Give your data set a good shuffle using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(X, y, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build learning curves, we need to check how the performance of our algorithm changes when using an increasing amount of data. We will check the scores that we obtain when using 20, 40, 60, 80 and 100% of our data set.\n",
    "\n",
    "The following lines demonstrate how to do this to create a new, smaller data set that contains the first 20% of your original data set:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_samples = X.shape[0] #total size of data set \n",
    "\n",
    "Xlittle, ylittle = X[:int(number_samples*0.2),:], y[:int(number_samples*0.2)] #what does this do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. Calculate the mean and the standard deviation of the 5-fold cross validation score for the data set above (don't forget to use 'f1' as the scoring parameter of the 'cross_val_score' function, otherwise it will default to accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. Now do the same but using 40, 60, 80 and 100% of your data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14\\. Based on the results you obtained, do you think getting more training data would help? (Justify your answer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Extra Credit </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "15\\. Save the values and plot the f1 score for the 5 models in a plot where \"percentage of the data set used\" (20, 40, ... 100%) is on the x axis and 'F1 score' is on the y axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\\. Do the same as above, but this time create an error bar plot where the y errors are given by the standard deviation of the scores you obtained in the 5 folds of the cross-validation. Why is the standard deviation information useful?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
