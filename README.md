# CBA's Portfolio:

This portfolio covers the following topics: Machine Learning Models (both classical and deep learning models), Mathematical Modeling using Discrete and Continuous Dynamical Systems, Data Structures and Algorithms, IoT/Embedded Systems, Drones, Red/Blue Teaming, and anything else that catches my eye. Formally, I'm an Applied Mathematics student but through my continuous exposure with different technologies/methods (while using Math as a base/springboard) I hope to co-op the title '***Hacker***'.


**Follow me throughout my journey.**

***Definition: Hacker | Hacker Culture - subculture of individuals who enjoy the intellectual challenge of creatively overcoming limitations of systems to achieve novel and clever outcomes***  

# Machine Learning In Astronomy Coursework:

* Spring 2019 PHYS3600ID: Machine Learning In Astronomy Coursework.

## RR Lyrae Dataset 

### Decision Tree Model | Cross Validation

* RR Lyrae are variable stars in the Lyra constellation. It plays a significant role in astronomy and has been studied extensively by Astronomers. The reason for this is because they are the brightest star in their class. This particular characteristic of RR Lyrae is important as it acts as a ***standard candle*** that can be used to meaure astronimical distances ([more on RR Lyrae here](https://en.wikipedia.org/wiki/RR_Lyrae_variable)). For this particular problem, we are presented with a dataset that contains 93141 instances (stars) with each instance containing 4 features which are the colors of the star. These colors which give an indication of whether a star emits more blue, green, yellow, or red light. We are also provided with the target vector implying that this is a supervised task. We use Decisions Trees in an attempt to classify the 93141 instances (stars) either as an RR Lyrae variable star or not. We also have an instance of unbalanced data here (we investigate the pitfalls of unbalanced data) and use methods in an attempt to resolve this issue. 

[View]()
[Download]() 

### Logistic Regressions Model

Using the RR Lyrae Dataset again, we continue to explore classification Machine Learning algorithms, particularly Logistic Regression. Logistic Regression despite its name is a Classification algorithm. Logistic Regression is modeled after the Logistic Function which itself is a type of Sigmoid Function. Sigmoid Functions are valuable in that that calculate the log-odds; Log-odds is an alternative representation of probabilities. A little more specifically, they represent odds of an event happening (the ratio of the probability of success to the probability of failure). Logistics Regression assigns weight (probabilities) to a particular instance which determines the odds of it falling in one *class* or the other. We explore the effectiveness of the algorithm as well as its pitfalls. 

[View]()
[Download]() 

## Study Hours Dataset 

### Linear Regression | Gradient Descent Model:

Here, we use the Study Hours Dataset. The Study Hours Dataset contains one feature vector (amount of hours studied) and one target vector (scores on the exam), both of which are continuous (There are no categories) so Regression seems appropriate here. It's a simple dataset which we'll use to illustrate the Linear Regression | Gradient Descent Models.  

[View]()
[Download]() 

## Higgs Boson Dataset

### Support Vector Machines:

### Ensemble Methods: Random Forests | Extremely Random Trees:

## Galaxies Dataset

### KMeans Clustering:

To illustrate the KMeans (unsupervised) clustering model, we use the Galaxies Dataset which is a collection of images of different types of Galaxies.  

### Convolutional | Deep Neural Networks:

# Python Modules:

## School_Toolkit: School Toolkit Module:

[View](https://github.com/deaththeberry/ML-AI-HKG_Portfolio/tree/master/Projects/School_Toolkit)

During the Fall 2018 semester, I took three interrelated courses dealing w/ Telecommunications, Digital Electronics, and Communication Electronics. When writing notes for the courses, I found myself having to do tedious calculations. Especially since I was typing my notes I decided that I should create a module that allowed me to access the functions without having to copy them from notebook to notebook. This module is a result of that problem.

# Mathematical Modeling of Continuous and Discrete Dynamical Systems Coursework:

## 

[Report]()
[Jupyter]() 

## 

[Report]()
[Jupyter]() 

## 

[Report]()
[Jupyter]() 